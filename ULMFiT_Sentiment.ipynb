{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ULMFiT Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vPYLLhCnN0i",
        "colab_type": "text"
      },
      "source": [
        "**ULMFiT model to Twitter US Airlines Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwHyl3UJl8q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libraries \n",
        "from fastai.text import * "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg83NGOnn2l1",
        "colab_type": "text"
      },
      "source": [
        "1. Data Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixik2gMnM5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing from csv \n",
        "dataset = pd.read_csv(\"Tweets.csv\")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyvXwgdNuAEt",
        "colab_type": "text"
      },
      "source": [
        "2. Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyWSxWj9uAfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# total number of tweets per each airline\n",
        "tweetsCount = dataset.groupby([\"airline\"])[\"tweet_id\"].count()\n",
        "tweetsCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zbDvnGvAYIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# horizontal bar graph showcasing the total number of tweets per each airline\n",
        "tweetsCount.plot.barh()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGgHuu-zEKZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# total number of tweets per each sentiment\n",
        "sentimentCount = dataset.groupby([\"airline_sentiment\"])[\"tweet_id\"].count()\n",
        "sentimentCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr08roYvEX5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vertical bar graph showcasing the total number of tweets per each airline\n",
        "sentimentCount.plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-abaGU38Axdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# total number of tweets per each airline of each sentiment\n",
        "tweetTypeCount = dataset.groupby([\"airline\", \"airline_sentiment\"])[\"tweet_id\"].count()\n",
        "tweetTypeCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKtmhuAVA-Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# color coded bar graph showing the total number of tweets per each airline of each sentiment\n",
        "tweetTypeCount.unstack().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLnKxzyjt0Mw",
        "colab_type": "text"
      },
      "source": [
        "3. Data Cleansing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VofAg1qDpYs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subsetting tweet text and sentiment label for modeling\n",
        "df = dataset[[\"airline_sentiment\", \"text\"]]\n",
        "df = df.rename(columns = {\"airline_sentiment\": \"label\"})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1myMyt4qbV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper functions to remove twitter handle name and unwanted characters from tweet text \n",
        " \n",
        "def removeHandleID(text):\n",
        "  text = re.sub('@[^\\s]+', '', text)\n",
        "  return text\n",
        "\n",
        "def removeExtraSpace(text):\n",
        "  text = re.sub(' {2,}', '', text)\n",
        "  return text\n",
        "\n",
        "def removeHashTags(text):\n",
        "  text = re.sub(r'([#])', r' \\1 ', text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJNPt2Burq-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaning the tweet texts \n",
        "df.text = df.text.apply(removeHandleID)\n",
        "df.text = df.text.apply(removeExtraSpace)\n",
        "df.text = df.text.apply(removeHashTags)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwIlJxLUs5Ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting dataset into training and validation sets \n",
        "validDF = df.sample(frac = 0.2)\n",
        "trainDF = df.drop(validDF.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymdx8qdkti5I",
        "colab_type": "text"
      },
      "source": [
        "4. Data Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYzEgFt4tXyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making data ready for modeling\n",
        "\n",
        "path = \"\"\n",
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = trainDF, \n",
        "                                  valid_df = validDF, \n",
        "                                  path = path)\n",
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = path, \n",
        "                                      train_df = trainDF, \n",
        "                                      valid_df = validDF, \n",
        "                                      vocab = data_lm.train_ds.vocab, \n",
        "                                      bs = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h98FBccUxioH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the preprocessed vocabulary mappings\n",
        "data_lm.save('data_lm_export.pkl')\n",
        "data_clas.save('data_clas_export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Eb07G4Uxm3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading the language data model\n",
        "data_lm = load_data(path, 'data_lm_export.pkl')\n",
        "data_clas = load_data(path, 'data_clas_export.pkl', bs=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IIwRZ8ZxwEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fine tuning language model \n",
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult = 0.5)\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssl2CCIeyIAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unfreezing the model in order to fine-tune it\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RaNnpqgybSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text completion prediction\n",
        "tempText = learn.predict(\"missing baggage\", n_words = 10)\n",
        "tempText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "273-vff2yyGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving model for transfer learning\n",
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNdTT_GXzFdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading ULMFit Model and building a classifier\n",
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult = 0.5)\n",
        "learn.load_encoder('ft_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9DDA7t-zKoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample batch of classified data\n",
        "data_clas.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIAQ4qV1zU5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning rate tuning\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj6mlid-zVbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unfreezing the model in order to fine-tune it\n",
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(5e-3/2., 5e-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZama5nszZ6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unfreezing the model in order to fine-tune it\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, slice(2e-3/100, 2e-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObQI4cOzuJy8",
        "colab_type": "text"
      },
      "source": [
        "5. Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo0l-ZdFuMlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculating accuracy from classification interpretation\n",
        "interpret = TextClassificationInterpretation.from_learner(learn)\n",
        "accuracy = accuracy(interpret.preds, interpret.y_true)\n",
        "print(\"Accuracy: {0:.3f}%\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SHyYKWA_IsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting a confusion matirx\n",
        "interpret.plot_confusion_matrix()\n",
        "plt.title(\"Confusion Matrix\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9gGeNVo7aKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample test \n",
        "tempText\n",
        "learn.predict(tempText)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}